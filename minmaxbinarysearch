#!/usr/bin/env python3

import strict_binary_search
import loose_binary_search
import random

from generator import *
from printer import *

# Parameters controlling what exactly gets tested.
haystack_candidates = ['Amy', 'Bay', 'Ben', 'Dan', 'Eve', 'Gus', 'Ian', 'Ivy', 'Joy', 'Kim', 'Lee', 'Liz', 'Max', 'May', 'Ray', 'Sam', 'Ted', 'Tom', 'Uma']
needle_candidates_not_in_haystack = ['Ada', 'Bea', 'Eva', 'Fay', 'Ned']
pagesize_candidates = [2, 10, 100, 1000]
truncation_lengths = [3, 2, 1]
execution_target_count = 5000
verbose_execution_limit = 10

truncation_specs = [ 'truncated_to_%d' % i for i in truncation_lengths ]

# Set up some global counters for averages.
total_step_count = {}
total_number_of_matching_pages = {}
execution_count = 0
for selector in ['full'] + truncation_specs:
    total_step_count[selector] = 0
    total_number_of_matching_pages[selector] = 0

# Test searching for existing and non-existing values separately.
for search_for_existing_value in [True, False]:
    if search_for_existing_value:
        print('\nLooking for existing values:')
    else:
        print('\nLooking for non-existing values:')

    print_table_header(truncation_lengths)

    # Execute a random search execution_target_count times.
    for execution_count in range(0, execution_target_count + 1):
        # Pick random search parameters based on the parameters.
        if search_for_existing_value:
            needle = random.choice(haystack_candidates)
        else:
            needle = random.choice(needle_candidates_not_in_haystack)
        elem_count = random.randint(10, 10000)
        haystack = generate_haystack(haystack_candidates, elem_count)
        pagesize = random.choice(pagesize_candidates)
        pages = generate_pages(haystack, pagesize, truncation_lengths)

        # Set up vars for the results and do the actual search.
        number_of_matching_pages = {}
        step_count = {}
        (number_of_matching_pages['full'], step_count['full']) = strict_binary_search.filter_pages(pages, needle)
        total_number_of_matching_pages['full'] += number_of_matching_pages['full']
        total_step_count['full'] += step_count['full']
        for truncation in truncation_specs:
            (number_of_matching_pages[truncation], step_count[truncation]) = loose_binary_search.filter_pages(pages, needle, truncation)
            total_number_of_matching_pages[truncation] += number_of_matching_pages[truncation]
            total_step_count[truncation] += step_count[truncation]

        # Only print up to verbose_execution_limit results.
        if execution_count < verbose_execution_limit:
            print_padded_integer(execution_count)
            print_padded_integer(elem_count)
            print_padded_integer(pagesize)
            print_padded_integer(len(pages))
            print_padded_string('')

            for selector in ['full'] + truncation_specs:
                print_padded_integer(step_count[selector])

            print_padded_string('')

            for selector in ['full'] + truncation_specs:
                print_padded_integer(number_of_matching_pages[selector])

            print()

    if verbose_execution_limit < execution_count:
        print('[%d executions omitted]' % (execution_count - verbose_execution_limit))
    print('-' * 140)

    # Print averages.
    print_padded_string('average')
    print_padded_string('')
    print_padded_string('')
    print_padded_string('')
    print_padded_string('')

    for selector in ['full'] + truncation_specs:
        print_padded_float(total_step_count[selector]/execution_count)

    print_padded_string('')

    for selector in ['full'] + truncation_specs:
        print_padded_float(total_number_of_matching_pages[selector]/execution_count)

    print()
